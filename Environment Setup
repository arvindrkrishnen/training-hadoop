#### Download HDP 2.1 Sandbox from the link - http://bit.ly/BigDataHadoopHiveTraining 
#### Play the sandbox from VMWare player and monitor the IP address as it comes on the screen
#### If you are using Windows, download putty. If Mac, you can directly connect to Sandbox on its IP address using the credentials root/hadoop through Putty or through Terminal Console in MAC
### Screenprints will be provided seperately
### Start Ambari

#### /root/start_ambari.sh

#### Check for Ambari by: typing http://<ipaddress>:8080 (Eg. http://192.168.226.130:8080/#/login ) - Use admin/admin as user id and password

Make the below config changes to Hive and YARN and restart these components

Under Hive config, increase memory settings:

hive.heapsize=512
hive.tez.container.size=512
hive.tez.java.opts=-Xmx410m

Under Hive config, turn on Hive txns:

hive.support.concurrency=true
hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager
hive.compactor.initiator.on=true
hive.compactor.worker.threads=2
hive.enforce.bucketing=true
hive.exec.dynamic.partition.mode=nonstrict

Under Hive config, enable Tez and sessions

hive.execution.engine=tez
hive.server2.tez.initialize.default.sessions=true
hive.server2.tez.default.queues=hive1,hive2
hive.server2.tez.sessions.per.default.queue=1
hive.server2.enable.doAs=false
hive.vectorized.groupby.maxentries=10240
hive.vectorized.groupby.flush.percent=0.1
Under YARN config, increase YARN memory settings:
yarn.nodemanager.resource.memory-mb=4096
yarn.scheduler.minimum-allocation-mb=512
yarn.scheduler.maximum-allocation-mb=4096

Under YARN config, under Capacity Scheduler, define queues - change these two existing properties:
yarn.scheduler.capacity.root.default.capacity=50
yarn.scheduler.capacity.root.queues=default,hiveserver  

Under YARN config, under Capacity Scheduler, define sub-queues - add below new properties:

yarn.scheduler.capacity.root.hiveserver.capacity=50
yarn.scheduler.capacity.root.hiveserver.hive1.capacity=50
yarn.scheduler.capacity.root.hiveserver.hive1.user-limit-factor=4
yarn.scheduler.capacity.root.hiveserver.hive2.capacity=50
yarn.scheduler.capacity.root.hiveserver.hive2.user-limit-factor=4
yarn.scheduler.capacity.root.hiveserver.queues=hive1,hive2

Under YARN config, under Custom yarn-site add these new properties to enable preemption:

yarn.resourcemanager.scheduler.monitor.enable=true
yarn.resourcemanager.scheduler.monitor.policies=org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy
yarn.resourcemanager.monitor.capacity.preemption.monitoring_interval=1000
yarn.resourcemanager.monitor.capacity.preemption.max_wait_before_kill=5000
yarn.resourcemanager.monitor.capacity.preemption.total_preemption_per_round=0.4

Restart Hive and Yarn post making the changes


Import data from MySQL to Hive ORC table via Sqoop

Download the data files for our analysis today:
http://1drv.ms/1EneUaO


Run below lines on terminal / console
cd /tmp
wget https://www.dropbox.com/s/idbkr6gwf7dd0nv/PII_Data.csv?dl=0
wget https://www.dropbox.com/s/nswffjex6c6k7nm/webtraffic.log?dl=0

mv PII_Data.csv?dl=0 PII_Data.csv
mv webtraffic.log?dl=0 webtraffic.log


Ingest into MySQL
mysql -u root -p
#empty password

create database people;
use people;
create table persons (people_id INT PRIMARY KEY, sex text, bdate DATE, firstname text, lastname text, addresslineone text, addresslinetwo text, city text, postalcode text, ssn text, id2 text, email text, id3 text);
LOAD DATA LOCAL INFILE '/tmp/PII_Data.csv'
REPLACE INTO TABLE persons FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n';
select people_id, firstname, lastname, city from persons;
exit;




